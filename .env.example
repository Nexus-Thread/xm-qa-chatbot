# OpenAI-compatible LLM API settings
# Base URL for provider endpoint (Ollama local by default)
OPENAI_BASE_URL=http://localhost:11434/v1
# API key used for provider authentication
OPENAI_API_KEY=replace-with-openai-api-key
# Model identifier used for extraction calls
OPENAI_MODEL=llama2
# Maximum retry attempts for transient LLM failures
OPENAI_MAX_RETRIES=3
# Base delay for exponential retry backoff (seconds)
OPENAI_BACKOFF_SECONDS=1.0
# Toggle TLS certificate verification for OpenAI HTTP calls
OPENAI_VERIFY_SSL=true
# OpenAI HTTP request timeout in seconds
OPENAI_TIMEOUT_SECONDS=30.0

# Storage settings
# SQLAlchemy connection URL
DATABASE_URL=sqlite:///./qa_chatbot.db
# SQLAlchemy SQL echo logging toggle
DATABASE_ECHO=false

# Dashboard generation settings
# Output directory for generated dashboard files
DASHBOARD_OUTPUT_DIR=./dashboard_html
# Script URL for Tailwind in browser dashboard templates
DASHBOARD_TAILWIND_SCRIPT_SRC=https://cdn.tailwindcss.com
# Script URL for Plotly in browser dashboard templates
DASHBOARD_PLOTLY_SCRIPT_SRC=https://cdn.plot.ly/plotly-2.27.0.min.js

# Jira adapter wiring settings
# Jira base URL used for generated links
JIRA_BASE_URL=https://jira.example.com
# Jira username for adapter wiring
JIRA_USERNAME=jira-user@example.com
# Jira API token for adapter wiring
JIRA_API_TOKEN=replace-with-jira-api-token

# Gradio UI settings
# Local server port for Gradio app
GRADIO_SERVER_PORT=7860
# Whether to generate a public Gradio share URL
GRADIO_SHARE=false

# Runtime safeguards and logging
# Application logging level (DEBUG/INFO/WARNING/ERROR)
LOG_LEVEL=INFO
# Maximum chat input length in characters
INPUT_MAX_CHARS=2000
# Max requests allowed per rate-limit window
RATE_LIMIT_REQUESTS=8
# Rate-limit window length in seconds
RATE_LIMIT_WINDOW_SECONDS=60
